{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install gradio safetensors yfinance optuna"
      ],
      "metadata": {
        "id": "63--JizIqSwI"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Xrpbxch7o4L_"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import yfinance as yf\n",
        "from safetensors.torch import save_file\n",
        "\n",
        "import optuna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ],
      "metadata": {
        "id": "aSgeqkTWLJRJ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# Model and Dataset Classes\n",
        "# -------------------------------\n",
        "class LSTMTimeSeries(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers=1, output_size=1):\n",
        "        super(LSTMTimeSeries, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = out[:, -1, :]\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "SU5yR2WIqYmZ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SPYDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.X[index], self.y[index]"
      ],
      "metadata": {
        "id": "tHwWYWxVqaFk"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# Helper Functions\n",
        "# -------------------------------\n",
        "def create_sequences(data, window_size=30, target_step=1):\n",
        "    X, y = [], []\n",
        "    num_samples = len(data)\n",
        "    for i in range(num_samples - window_size - target_step + 1):\n",
        "        X_seq = data[i : i + window_size]\n",
        "        y_seq = data[i + window_size + target_step - 1]\n",
        "        X.append(X_seq)\n",
        "        y.append(y_seq[3])  # Only predict 'Close' (index = 3)\n",
        "    return np.array(X), np.array(y)"
      ],
      "metadata": {
        "id": "j5IlowMlqbtb"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data_for_tuning(ticker, start_date, end_date,\n",
        "                         sequence_length=30,\n",
        "                         prediction_days=1,\n",
        "                         val_ratio=0.1, test_ratio=0.1):\n",
        "    \"\"\"\n",
        "    Fetch data, create sequences, and split into train/val/test sets.\n",
        "    val_ratio and test_ratio are fractions of the entire dataset used for validation and test.\n",
        "    \"\"\"\n",
        "    # Fetch data\n",
        "    spy_df = yf.download(ticker, start=start_date, end=end_date)\n",
        "    spy_df.reset_index(inplace=True)\n",
        "\n",
        "    features = ['Open', 'High', 'Low', 'Close']\n",
        "    data = spy_df[features].values\n",
        "\n",
        "    # Scale data\n",
        "    scaler = MinMaxScaler()\n",
        "    data_scaled = scaler.fit_transform(data)\n",
        "\n",
        "    # Create sequences\n",
        "    X_all, y_all = create_sequences(data_scaled, window_size=sequence_length, target_step=prediction_days)\n",
        "\n",
        "    # Train/val/test split\n",
        "    dataset_size = len(X_all)\n",
        "    val_size = int(val_ratio * dataset_size)\n",
        "    test_size = int(test_ratio * dataset_size)\n",
        "    train_size = dataset_size - val_size - test_size\n",
        "\n",
        "    X_train, X_val, X_test = X_all[:train_size], X_all[train_size:train_size+val_size], X_all[train_size+val_size:]\n",
        "    y_train, y_val, y_test = y_all[:train_size], y_all[train_size:train_size+val_size], y_all[train_size+val_size:]\n",
        "\n",
        "    return X_train, y_train, X_val, y_val, X_test, y_test, scaler, data"
      ],
      "metadata": {
        "id": "wHos3ffQJJNl"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# Objective Function for Optuna\n",
        "# -------------------------------\n",
        "def objective(trial, ticker, start_date, end_date,\n",
        "              sequence_length=30,\n",
        "              prediction_days=1,\n",
        "              n_epochs=10,\n",
        "              val_ratio=0.1,\n",
        "              test_ratio=0.1):\n",
        "\n",
        "    \"\"\"\n",
        "    Objective function that Optuna will call multiple times,\n",
        "    each time sampling different hyperparameters.\n",
        "    \"\"\"\n",
        "\n",
        "    # -----------------------------\n",
        "    # 1) Suggest hyperparameters\n",
        "    # -----------------------------\n",
        "    hidden_size = trial.suggest_int(\"hidden_size\", 32, 256, step=32)\n",
        "    num_layers = trial.suggest_int(\"num_layers\", 1, 3)\n",
        "    lr = trial.suggest_float(\"lr\", 1e-4, 0.1, log=True)\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64, 128])\n",
        "\n",
        "    # -----------------------------\n",
        "    # 2) Load data\n",
        "    # -----------------------------\n",
        "    X_train, y_train, X_val, y_val, X_test, y_test, scaler, data = load_data_for_tuning(\n",
        "        ticker, start_date, end_date,\n",
        "        sequence_length=sequence_length,\n",
        "        prediction_days=prediction_days,\n",
        "        val_ratio=val_ratio,\n",
        "        test_ratio=test_ratio\n",
        "    )\n",
        "\n",
        "    # -----------------------------\n",
        "    # 3) Create DataLoaders\n",
        "    # -----------------------------\n",
        "    train_dataset = SPYDataset(X_train, y_train)\n",
        "    val_dataset   = SPYDataset(X_val, y_val)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # -----------------------------\n",
        "    # 4) Define model, loss, opt\n",
        "    # -----------------------------\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    input_size = 4  # ['Open', 'High', 'Low', 'Close']\n",
        "    output_size = 1\n",
        "\n",
        "    model = LSTMTimeSeries(input_size, hidden_size, num_layers, output_size).to(device)\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    # -----------------------------\n",
        "    # 5) Train\n",
        "    # -----------------------------\n",
        "    model.train()\n",
        "    for epoch in range(n_epochs):\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            X_batch = X_batch.to(device)\n",
        "            y_batch = y_batch.to(device).unsqueeze(1)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(X_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # -----------------------------\n",
        "    # 6) Validation\n",
        "    # -----------------------------\n",
        "    model.eval()\n",
        "    val_predictions, val_actuals = [], []\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in val_loader:\n",
        "            X_batch = X_batch.to(device)\n",
        "            outputs = model(X_batch)\n",
        "            val_predictions.append(outputs.cpu().numpy())\n",
        "            val_actuals.append(y_batch.numpy().reshape(-1, 1))\n",
        "\n",
        "    val_predictions = np.vstack(val_predictions)\n",
        "    val_actuals = np.vstack(val_actuals)\n",
        "\n",
        "    # Invert scaling for 'Close'\n",
        "    pred_close_scaled = np.zeros((len(val_predictions), data.shape[1]))\n",
        "    act_close_scaled = np.zeros((len(val_actuals), data.shape[1]))\n",
        "\n",
        "    # Remember: data.shape[1] = 4\n",
        "    pred_close_scaled[:, 3] = val_predictions.flatten()\n",
        "    act_close_scaled[:, 3] = val_actuals.flatten()\n",
        "\n",
        "    pred_close = scaler.inverse_transform(pred_close_scaled)[:, 3]\n",
        "    act_close  = scaler.inverse_transform(act_close_scaled)[:, 3]\n",
        "\n",
        "    rmse_val = float(np.sqrt(np.mean((pred_close - act_close) ** 2)))\n",
        "\n",
        "    return rmse_val"
      ],
      "metadata": {
        "id": "pJaEZoNGJPdk"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# Run Optuna Tuning\n",
        "# -------------------------------\n",
        "def tune_hyperparams(ticker=\"SPY\",\n",
        "                     start_date=\"2020-01-24\",\n",
        "                     end_date=\"2025-01-31\",\n",
        "                     sequence_length=30,\n",
        "                     prediction_days=1,\n",
        "                     n_epochs=10,\n",
        "                     val_ratio=0.1,\n",
        "                     test_ratio=0.1,\n",
        "                     n_trials=20):\n",
        "    \"\"\"\n",
        "    Runs an Optuna study to tune hyperparameters of the LSTM model.\n",
        "    Returns the best hyperparameters.\n",
        "    \"\"\"\n",
        "    def optuna_objective(trial):\n",
        "        return objective(\n",
        "            trial,\n",
        "            ticker=ticker,\n",
        "            start_date=start_date,\n",
        "            end_date=end_date,\n",
        "            sequence_length=sequence_length,\n",
        "            prediction_days=prediction_days,\n",
        "            n_epochs=n_epochs,\n",
        "            val_ratio=val_ratio,\n",
        "            test_ratio=test_ratio\n",
        "        )\n",
        "\n",
        "    study = optuna.create_study(direction=\"minimize\")\n",
        "    study.optimize(optuna_objective, n_trials=n_trials)\n",
        "\n",
        "    print(\"Best trial:\", study.best_trial)\n",
        "    print(\"Best RMSE:\", study.best_value)\n",
        "    print(\"Best hyperparameters:\", study.best_params)\n",
        "    return study.best_params"
      ],
      "metadata": {
        "id": "1UgIBBKjJQhG"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_or_train_model(train_loader, input_size, hidden_size, num_layers, output_size,\n",
        "                       epochs, lr, model_file=\"lstm_model.safetensors\"):\n",
        "    \"\"\"\n",
        "    Tries to load a model from a safetensors file. If it does not exist (or fails to load),\n",
        "    trains a new model using the provided training DataLoader and hyperparameters,\n",
        "    then saves the model in safetensors format.\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = LSTMTimeSeries(input_size, hidden_size, num_layers, output_size).to(device)\n",
        "\n",
        "    try:\n",
        "        if os.path.exists(model_file):\n",
        "            print(f\"Loading existing model from {model_file}...\")\n",
        "            loaded_state_dict = load_file(model_file)\n",
        "            model.load_state_dict(loaded_state_dict)\n",
        "        else:\n",
        "            raise FileNotFoundError\n",
        "    except Exception as e:\n",
        "        print(\"Model not found or failed to load; training new model...\")\n",
        "        criterion = nn.MSELoss()\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "        model.train()\n",
        "        for epoch in range(epochs):\n",
        "            epoch_loss = 0.0\n",
        "            for X_batch, y_batch in train_loader:\n",
        "                X_batch = X_batch.to(device)\n",
        "                y_batch = y_batch.to(device).unsqueeze(1)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(X_batch)\n",
        "                loss = criterion(outputs, y_batch)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                epoch_loss += loss.item() * X_batch.size(0)\n",
        "            epoch_loss /= len(train_loader.dataset)\n",
        "            print(f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.6f}\")\n",
        "\n",
        "        # Save the trained model as a safetensor\n",
        "        state_dict_cpu = {k: v.cpu() for k, v in model.state_dict().items()}\n",
        "        save_file(state_dict_cpu, model_file)\n",
        "        print(f\"New model saved as {model_file}\")\n",
        "\n",
        "    # Set model to evaluation mode for inference\n",
        "    model.eval()\n",
        "    return model"
      ],
      "metadata": {
        "id": "Ch3JS4vyhJyO"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# Predict & Forecast Function\n",
        "# -------------------------------\n",
        "def predict_spy(ticker, start_date, end_date,\n",
        "                prediction_days=1,\n",
        "                sequence_length=30,\n",
        "                epochs=10,\n",
        "                forecast_days=5,\n",
        "                # Optionally pass tuned params or use defaults\n",
        "                hidden_size=64,\n",
        "                num_layers=1,\n",
        "                lr=1e-3,\n",
        "                batch_size=32):\n",
        "    \"\"\"\n",
        "    Main function to fetch data from Yahoo Finance, train the LSTM, and extend predictions to future days.\n",
        "    Optionally uses hyperparameters from Optuna (if you supply them).\n",
        "    \"\"\"\n",
        "    spy_df = yf.download(ticker, start=start_date, end=end_date)\n",
        "    spy_df.reset_index(inplace=True)\n",
        "\n",
        "    features = ['Open', 'High', 'Low', 'Close']\n",
        "    data = spy_df[features].values\n",
        "\n",
        "    # Scale data\n",
        "    scaler = MinMaxScaler()\n",
        "    data_scaled = scaler.fit_transform(data)\n",
        "\n",
        "    # Create sequences\n",
        "    X_all, y_all = create_sequences(data_scaled, window_size=sequence_length, target_step=prediction_days)\n",
        "\n",
        "    # Train/test split (80/20)\n",
        "    train_size = int(0.8 * len(X_all))\n",
        "    X_train, X_test = X_all[:train_size], X_all[train_size:]\n",
        "    y_train, y_test = y_all[:train_size], y_all[train_size:]\n",
        "\n",
        "    # Datasets & Loaders\n",
        "    train_dataset = SPYDataset(X_train, y_train)\n",
        "    test_dataset  = SPYDataset(X_test,  y_test)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Model setup\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    input_size = len(features)\n",
        "    output_size = 1\n",
        "\n",
        "    model = LSTMTimeSeries(input_size, hidden_size, num_layers, output_size).to(device)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    # Try to load an existing model; if not found, train a new one\n",
        "    model = get_or_train_model(train_loader, input_size, hidden_size, num_layers,\n",
        "                               output_size, epochs, lr, model_file=\"lstm_model.safetensors\")\n",
        "\n",
        "    # Training\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0.0\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            X_batch = X_batch.to(device)\n",
        "            y_batch = y_batch.to(device).unsqueeze(1)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(X_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item() * X_batch.size(0)\n",
        "        epoch_loss /= len(train_loader.dataset)\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.6f}\")\n",
        "\n",
        "    # Predictions on test set\n",
        "    model.eval()\n",
        "    predictions, actuals = [], []\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in test_loader:\n",
        "            X_batch = X_batch.to(device)\n",
        "            outputs = model(X_batch)\n",
        "            predictions.append(outputs.cpu().numpy())\n",
        "            actuals.append(y_batch.numpy().reshape(-1, 1))\n",
        "\n",
        "    predictions = np.vstack(predictions)\n",
        "    actuals     = np.vstack(actuals)\n",
        "\n",
        "    # Invert scaling (Close only)\n",
        "    pred_close_scaled = np.zeros((len(predictions), data.shape[1]))\n",
        "    act_close_scaled  = np.zeros((len(actuals), data.shape[1]))\n",
        "\n",
        "    pred_close_scaled[:, 3] = predictions.flatten()\n",
        "    act_close_scaled[:, 3]  = actuals.flatten()\n",
        "\n",
        "    pred_close = scaler.inverse_transform(pred_close_scaled)[:, 3]\n",
        "    act_close  = scaler.inverse_transform(act_close_scaled)[:, 3]\n",
        "\n",
        "    mse  = np.mean((pred_close - act_close) ** 2)\n",
        "    rmse = float(np.sqrt(mse))\n",
        "\n",
        "    # Forecast future prices\n",
        "    future_predictions = []\n",
        "    last_sequence = data_scaled[-sequence_length:]  # Last available sequence\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(forecast_days):\n",
        "            last_seq_tensor = torch.tensor(last_sequence, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "            next_scaled_price = model(last_seq_tensor).cpu().numpy()\n",
        "\n",
        "            # Insert into a zero vector so we can invert scale\n",
        "            next_scaled_price_full = np.zeros((1, data.shape[1]))\n",
        "            next_scaled_price_full[0, 3] = next_scaled_price\n",
        "            next_price = scaler.inverse_transform(next_scaled_price_full)[0, 3]\n",
        "\n",
        "            future_predictions.append(next_price)\n",
        "\n",
        "            # Shift sequence and add new predicted close\n",
        "            next_sequence = np.roll(last_sequence, -1, axis=0)\n",
        "            next_sequence[-1, 3] = next_scaled_price\n",
        "            last_sequence = next_sequence\n",
        "\n",
        "    # Combine predictions and future forecasts\n",
        "    forecast_indices = np.arange(len(act_close), len(act_close) + forecast_days)\n",
        "    fig = go.Figure()\n",
        "    fig.add_trace(go.Scatter(y=act_close, mode='lines', name='Actual Close'))\n",
        "    fig.add_trace(go.Scatter(y=pred_close, mode='lines', name='Predicted Close'))\n",
        "    fig.add_trace(go.Scatter(x=forecast_indices, y=future_predictions,\n",
        "                             mode='lines', name='Forecasted Prices',\n",
        "                             line=dict(dash='dot')))\n",
        "\n",
        "    fig.update_layout(\n",
        "        title=f'{ticker} Actual, Predicted, and Forecasted Close Prices',\n",
        "        xaxis_title='Index',\n",
        "        yaxis_title='Price'\n",
        "    )\n",
        "\n",
        "    # Make sure to move tensors to CPU before saving (safetensors works best with CPU tensors)\n",
        "    state_dict_cpu = {k: v.cpu() for k, v in model.state_dict().items()}\n",
        "\n",
        "    # Save the state dictionary to a file named \"lstm_model.safetensors\"\n",
        "    save_file(state_dict_cpu, \"lstm_model.safetensors\")\n",
        "    print(\"Model saved as lstm_model.safetensors\")\n",
        "\n",
        "    return fig, rmse"
      ],
      "metadata": {
        "id": "4Kg3w0lEqeEz"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ticker = \"SPY\"\n",
        "start_date=\"2021-01-24\"\n",
        "end_date=\"2025-02-09\"\n",
        "prediction_days=1"
      ],
      "metadata": {
        "id": "l6SYKBPRKrmH"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate best hyperparameters\n",
        "best_params = tune_hyperparams(\n",
        "    ticker=ticker,\n",
        "    start_date=start_date,\n",
        "    end_date=end_date,\n",
        "    sequence_length=30,\n",
        "    prediction_days=prediction_days,\n",
        "    n_epochs=10,\n",
        "    val_ratio=0.1,\n",
        "    test_ratio=0.1,\n",
        "    n_trials=20\n",
        ")\n",
        "print(best_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-MqTEGnJnP4",
        "outputId": "1b4c7a43-596e-4c24-aaa2-c64a918fea1a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-09 21:04:23,802] A new study created in memory with name: no-name-b329c076-0b8a-471b-9e6c-7a978df002bf\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[I 2025-02-09 21:04:25,225] Trial 0 finished with value: 130.75962542992391 and parameters: {'hidden_size': 192, 'num_layers': 1, 'lr': 0.06208813965888773, 'batch_size': 16}. Best is trial 0 with value: 130.75962542992391.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[I 2025-02-09 21:04:25,536] Trial 1 finished with value: 45.429668151885295 and parameters: {'hidden_size': 224, 'num_layers': 1, 'lr': 0.0003560959275959684, 'batch_size': 128}. Best is trial 1 with value: 45.429668151885295.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[I 2025-02-09 21:04:26,190] Trial 2 finished with value: 34.74052328356455 and parameters: {'hidden_size': 64, 'num_layers': 1, 'lr': 0.09641401676052264, 'batch_size': 32}. Best is trial 2 with value: 34.74052328356455.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[I 2025-02-09 21:04:26,671] Trial 3 finished with value: 7.596877091265167 and parameters: {'hidden_size': 160, 'num_layers': 1, 'lr': 0.007917467125379628, 'batch_size': 128}. Best is trial 3 with value: 7.596877091265167.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[I 2025-02-09 21:04:26,995] Trial 4 finished with value: 8.883522760222645 and parameters: {'hidden_size': 256, 'num_layers': 1, 'lr': 0.0011940602291987297, 'batch_size': 128}. Best is trial 3 with value: 7.596877091265167.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[I 2025-02-09 21:04:27,306] Trial 5 finished with value: 68.63287063069939 and parameters: {'hidden_size': 224, 'num_layers': 1, 'lr': 0.000324288250929856, 'batch_size': 128}. Best is trial 3 with value: 7.596877091265167.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[I 2025-02-09 21:04:27,631] Trial 6 finished with value: 143.24866905314616 and parameters: {'hidden_size': 128, 'num_layers': 2, 'lr': 0.03487133249587792, 'batch_size': 128}. Best is trial 3 with value: 7.596877091265167.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[I 2025-02-09 21:04:29,045] Trial 7 finished with value: 9.231781319090372 and parameters: {'hidden_size': 192, 'num_layers': 2, 'lr': 0.005474170529662449, 'batch_size': 128}. Best is trial 3 with value: 7.596877091265167.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[I 2025-02-09 21:04:29,333] Trial 8 finished with value: 9.64071646962711 and parameters: {'hidden_size': 64, 'num_layers': 2, 'lr': 0.004028576606888094, 'batch_size': 128}. Best is trial 3 with value: 7.596877091265167.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[I 2025-02-09 21:04:29,832] Trial 9 finished with value: 11.148450893955175 and parameters: {'hidden_size': 96, 'num_layers': 3, 'lr': 0.007172272800148429, 'batch_size': 64}. Best is trial 3 with value: 7.596877091265167.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[I 2025-02-09 21:04:32,245] Trial 10 finished with value: 126.89146285596684 and parameters: {'hidden_size': 160, 'num_layers': 3, 'lr': 0.015750838390772022, 'batch_size': 16}. Best is trial 3 with value: 7.596877091265167.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[I 2025-02-09 21:04:33,161] Trial 11 finished with value: 10.0843281410639 and parameters: {'hidden_size': 256, 'num_layers': 1, 'lr': 0.001188948472938098, 'batch_size': 32}. Best is trial 3 with value: 7.596877091265167.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[I 2025-02-09 21:04:33,643] Trial 12 finished with value: 8.252315760604093 and parameters: {'hidden_size': 256, 'num_layers': 1, 'lr': 0.0016824267839247718, 'batch_size': 64}. Best is trial 3 with value: 7.596877091265167.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[I 2025-02-09 21:04:34,077] Trial 13 finished with value: 8.718065027095447 and parameters: {'hidden_size': 128, 'num_layers': 2, 'lr': 0.0011406677457235703, 'batch_size': 64}. Best is trial 3 with value: 7.596877091265167.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[I 2025-02-09 21:04:34,438] Trial 14 finished with value: 137.13766318953523 and parameters: {'hidden_size': 32, 'num_layers': 1, 'lr': 0.0001250266648936354, 'batch_size': 64}. Best is trial 3 with value: 7.596877091265167.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[I 2025-02-09 21:04:35,386] Trial 15 finished with value: 129.42713075284465 and parameters: {'hidden_size': 160, 'num_layers': 2, 'lr': 0.014024939519089957, 'batch_size': 64}. Best is trial 3 with value: 7.596877091265167.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[I 2025-02-09 21:04:36,155] Trial 16 finished with value: 6.979470906815442 and parameters: {'hidden_size': 192, 'num_layers': 1, 'lr': 0.0021489302541457334, 'batch_size': 64}. Best is trial 16 with value: 6.979470906815442.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[I 2025-02-09 21:04:38,466] Trial 17 finished with value: 136.25501890990728 and parameters: {'hidden_size': 192, 'num_layers': 3, 'lr': 0.012145648685518125, 'batch_size': 32}. Best is trial 16 with value: 6.979470906815442.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[I 2025-02-09 21:04:40,375] Trial 18 finished with value: 9.341135427006764 and parameters: {'hidden_size': 160, 'num_layers': 2, 'lr': 0.0024689245458686462, 'batch_size': 16}. Best is trial 16 with value: 6.979470906815442.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[I 2025-02-09 21:04:40,747] Trial 19 finished with value: 12.594010654185896 and parameters: {'hidden_size': 96, 'num_layers': 1, 'lr': 0.0005492095911035311, 'batch_size': 64}. Best is trial 16 with value: 6.979470906815442.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial: FrozenTrial(number=16, state=1, values=[6.979470906815442], datetime_start=datetime.datetime(2025, 2, 9, 21, 4, 35, 387082), datetime_complete=datetime.datetime(2025, 2, 9, 21, 4, 36, 154991), params={'hidden_size': 192, 'num_layers': 1, 'lr': 0.0021489302541457334, 'batch_size': 64}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'hidden_size': IntDistribution(high=256, log=False, low=32, step=32), 'num_layers': IntDistribution(high=3, log=False, low=1, step=1), 'lr': FloatDistribution(high=0.1, log=True, low=0.0001, step=None), 'batch_size': CategoricalDistribution(choices=(16, 32, 64, 128))}, trial_id=16, value=None)\n",
            "Best RMSE: 6.979470906815442\n",
            "Best hyperparameters: {'hidden_size': 192, 'num_layers': 1, 'lr': 0.0021489302541457334, 'batch_size': 64}\n",
            "{'hidden_size': 192, 'num_layers': 1, 'lr': 0.0021489302541457334, 'batch_size': 64}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pass into prediction model\n",
        "fig, rmse = predict_spy(\n",
        "    ticker=ticker,\n",
        "    start_date=start_date,\n",
        "    end_date=end_date,\n",
        "    prediction_days=prediction_days,\n",
        "    sequence_length=30,\n",
        "    epochs=10,\n",
        "    forecast_days=5,\n",
        "    hidden_size=best_params[\"hidden_size\"],\n",
        "    num_layers=best_params[\"num_layers\"],\n",
        "    lr=best_params[\"lr\"],\n",
        "    batch_size=best_params[\"batch_size\"]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxclgw5NJtpD",
        "outputId": "59fee93d-424e-498c-e335-326475d6d3bf"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model not found or failed to load; training new model...\n",
            "Epoch [1/10], Loss: 0.031693\n",
            "Epoch [2/10], Loss: 0.005383\n",
            "Epoch [3/10], Loss: 0.001451\n",
            "Epoch [4/10], Loss: 0.000808\n",
            "Epoch [5/10], Loss: 0.000610\n",
            "Epoch [6/10], Loss: 0.000585\n",
            "Epoch [7/10], Loss: 0.000550\n",
            "Epoch [8/10], Loss: 0.000539\n",
            "Epoch [9/10], Loss: 0.000536\n",
            "Epoch [10/10], Loss: 0.000530\n",
            "New model saved as lstm_model.safetensors\n",
            "Epoch [1/10], Loss: 0.000520\n",
            "Epoch [2/10], Loss: 0.000520\n",
            "Epoch [3/10], Loss: 0.000520\n",
            "Epoch [4/10], Loss: 0.000520\n",
            "Epoch [5/10], Loss: 0.000520\n",
            "Epoch [6/10], Loss: 0.000520\n",
            "Epoch [7/10], Loss: 0.000520\n",
            "Epoch [8/10], Loss: 0.000520\n",
            "Epoch [9/10], Loss: 0.000520\n",
            "Epoch [10/10], Loss: 0.000520\n",
            "Model saved as lstm_model.safetensors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# Gradio Interface\n",
        "# -------------------------------\n",
        "demo = gr.Interface(\n",
        "    fn=predict_spy,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Enter Ticker Symbol\", placeholder=\"e.g., SPY\", value=\"SPY\"),\n",
        "        gr.Textbox(label=\"Start Date\", value=\"2019-01-24\"),\n",
        "        gr.Textbox(label=\"End Date\", value=\"2025-01-28\"),\n",
        "        gr.Slider(label=\"Prediction Days Ahead\", minimum=1, maximum=30, value=1, step=1),\n",
        "        gr.Slider(label=\"Sequence Length\", minimum=10, maximum=200, value=60, step=5),\n",
        "        gr.Slider(label=\"Number of Epochs\", minimum=1, maximum=50, value=10, step=1),\n",
        "        gr.Slider(label=\"Forecast Days\", minimum=1, maximum=60, value=30, step=1)\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Plot(label=\"Predictions and Forecast\"),\n",
        "        gr.Number(label=\"RMSE\")\n",
        "    ],\n",
        "    description=(\n",
        "        \"Enter a stock ticker symbol (e.g., SPY) to fetch historical data from Yahoo Finance. \"\n",
        "        \"Adjust the date range, prediction days, sequence length, and training epochs. \"\n",
        "        \"The model predicts and forecasts future prices.\"\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "juN-ZT3gKP0c"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Run hyperparameter tuning first (optional)\n",
        "    # Then pass them into predict_spy (for instance) in your actual usage.\n",
        "\n",
        "    demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "id": "RiZxQX5gJZKy",
        "outputId": "43e85f71-d52d-4f6c-d75e-9837c2e4ef5c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://2f20ce5d00be2ef06b.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://2f20ce5d00be2ef06b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}