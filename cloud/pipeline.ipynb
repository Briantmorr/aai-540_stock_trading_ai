{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r ./requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "from sagemaker.workflow.function_step import step\n",
    "from sagemaker import get_execution_role, Session\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from steps.fetch import fetch\n",
    "from steps.preprocess import preprocess\n",
    "from steps.train import train\n",
    "from steps.eval import eval\n",
    "from steps.deploy import deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = Session()\n",
    "role = get_execution_role()\n",
    "\n",
    "default_bucket = sagemaker_session.default_bucket()\n",
    "session = PipelineSession(boto_session=sagemaker_session.boto_session, default_bucket=default_bucket)\n",
    "pipeline_name = 'stock-pipeline'\n",
    "default_ticker = \"SPY\"\n",
    "years_of_data_to_fetch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @step(\n",
    "#     instance_type=\"ml.m5.large\"\n",
    "# )\n",
    "# def train(data):\n",
    "#     # retrieve preprocessed csv data\n",
    "#     # train model\n",
    "#     # save model to s3 bucket /model with postfix of date and RMSE in filename\n",
    "#     logging.info(f'data should be output of preprocess function: {data}')\n",
    "#     return \"stub_train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @step(\n",
    "#     instance_type=\"ml.m5.large\"\n",
    "# )\n",
    "# def eval(data):\n",
    "#     # load current model file and latest\n",
    "#     # extract model performance from RSME in filename\n",
    "#     # if model is better than current\n",
    "#     # pass True to deploy phase (Use conditional to assess when to run deploy)\n",
    "#     logging.info(f'data should be output of preprocess function: {data}')\n",
    "#     return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @step(\n",
    "#     instance_type=\"ml.m5.large\"\n",
    "# )\n",
    "# def deploy(data):\n",
    "#     # if latest_model is different than current\n",
    "#     # update deployment to use latest model\n",
    "#     logging.info(f'data should be output of train function: {data}')\n",
    "#     return \"stub_eval\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:steps.utils:Successfully fetched data for SPY\n",
      "INFO:steps.utils:Raw data saved to s3://sagemaker-us-east-1-971173012767/raw/SPY_raw_data.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-971173012767/raw/SPY_raw_data.csv\n"
     ]
    }
   ],
   "source": [
    "fetch_result = fetch(default_ticker, years_of_data_to_fetch)\n",
    "print(fetch_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:steps.utils:Starting preprocessing with data from s3://sagemaker-us-east-1-971173012767/raw/SPY_raw_data.csv\n",
      "INFO:steps.utils:Successfully read raw data from s3://sagemaker-us-east-1-971173012767/raw/SPY_raw_data.csv\n",
      "INFO:steps.utils:Data preprocessing completed\n",
      "INFO:steps.utils:Preprocessed data saved to s3://sagemaker-us-east-1-971173012767/processed/processed/SPY_processed_data.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-971173012767/processed/processed/SPY_processed_data.csv\n"
     ]
    }
   ],
   "source": [
    "preprocess_result = preprocess(fetch_result)\n",
    "print(preprocess_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:steps.utils:Starting training with data from s3://sagemaker-us-east-1-971173012767/processed/processed/SPY_processed_data.csv\n",
      "INFO:steps.utils:Loaded preprocessed data with shape (250, 4)\n",
      "INFO:steps.utils:Epoch 1/10, Loss: 0.40415561695893604\n",
      "INFO:steps.utils:Epoch 2/10, Loss: 0.25259753316640854\n",
      "INFO:steps.utils:Epoch 3/10, Loss: 0.09453133183221023\n",
      "INFO:steps.utils:Epoch 4/10, Loss: 0.03746751012901465\n",
      "INFO:steps.utils:Epoch 5/10, Loss: 0.02119459956884384\n",
      "INFO:steps.utils:Epoch 6/10, Loss: 0.020061183410386246\n",
      "INFO:steps.utils:Epoch 7/10, Loss: 0.016886258653054636\n",
      "INFO:steps.utils:Epoch 8/10, Loss: 0.011630564772834381\n",
      "INFO:steps.utils:Epoch 9/10, Loss: 0.01056354803343614\n",
      "INFO:steps.utils:Epoch 10/10, Loss: 0.008187109914918741\n",
      "INFO:steps.utils:Training completed with RMSE: 12.677477423538493\n",
      "INFO:steps.utils:Model saved to s3://sagemaker-us-east-1-971173012767/model/model_20250221_23_rmse_12.6775.safetensors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('s3://sagemaker-us-east-1-971173012767/model/model_20250221_23_rmse_12.6775.safetensors', 12.677477423538493)\n"
     ]
    }
   ],
   "source": [
    "train_result = train(preprocess_result)\n",
    "print(train_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:steps.utils:Evaluating model from s3://sagemaker-us-east-1-971173012767/model/model_20250221_23_rmse_12.6775.safetensors with RMSE: 12.677477423538493\n",
      "INFO:steps.utils:Loaded model from s3://sagemaker-us-east-1-971173012767/model/model_20250221_23_rmse_12.6775.safetensors\n",
      "INFO:steps.utils:No current model found or error loading s3://sagemaker-us-east-1-971173012767/model/current_model.safetensors: An error occurred (NoSuchKey) when calling the GetObject operation: The specified key does not exist.. Assuming new model is better.\n",
      "INFO:steps.utils:New RMSE: 12.677477423538493, Current RMSE: inf, Deploy: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(True, 's3://sagemaker-us-east-1-971173012767/model/model_20250221_23_rmse_12.6775.safetensors')\n"
     ]
    }
   ],
   "source": [
    "eval_result = eval(train_result)\n",
    "print(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:steps.utils:Received eval output: deploy_flag=True, model_s3_path=s3://sagemaker-us-east-1-971173012767/model/model_20250221_23_rmse_12.6775.safetensors\n",
      "INFO:steps.utils:Loaded model from s3://sagemaker-us-east-1-971173012767/model/model_20250221_23_rmse_12.6775.safetensors\n",
      "INFO:steps.utils:Model artifacts uploaded to s3://sagemaker-us-east-1-971173012767/model/model.tar.gz\n",
      "INFO:sagemaker:Repacking model artifact (s3://sagemaker-us-east-1-971173012767/model/model.tar.gz), script artifact (/home/sagemaker-user/aai-540_stock_trading_ai/cloud/steps), and dependencies ([]) into single tar.gz file located at s3://sagemaker-us-east-1-971173012767/pytorch-inference-2025-02-21-23-40-58-073/model.tar.gz. This may take some time depending on model size...\n",
      "INFO:sagemaker:Creating model with name: pytorch-inference-2025-02-21-23-40-58-670\n",
      "INFO:sagemaker:Creating endpoint-config with name stock-pipeline-endpoint-20250221-234058\n",
      "INFO:sagemaker:Creating endpoint with name stock-pipeline-endpoint-20250221-234058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------!"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:steps.utils:Model deployed to endpoint: stock-pipeline-endpoint-20250221-234058\n",
      "INFO:steps.utils:Updated current model at s3://sagemaker-us-east-1-971173012767/model/current_model.safetensors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stock-pipeline-endpoint-20250221-234058\n"
     ]
    }
   ],
   "source": [
    "deploy_result = deploy(eval_result)\n",
    "print(deploy_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    steps=[fetch_result, preprocess_result, train_result, eval_result, deploy_result],\n",
    "    sagemaker_session=session,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 20:50:38,084 sagemaker.remote_function INFO     Uploading serialized function code to s3://sagemaker-us-east-1-971173012767/stock-pipeline/fetch-80b1c5ef-0734-4a54-9399-a435f0087fff/2025-02-21-20-50-37-995/function\n",
      "2025-02-21 20:50:38,258 sagemaker.remote_function INFO     Uploading serialized function arguments to s3://sagemaker-us-east-1-971173012767/stock-pipeline/fetch-80b1c5ef-0734-4a54-9399-a435f0087fff/2025-02-21-20-50-37-995/arguments\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid dependencies provided: \"cloud/\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrole\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/workflow/pipeline.py:292\u001b[0m, in \u001b[0;36mPipeline.upsert\u001b[0;34m(self, role_arn, description, tags, parallelism_config)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn AWS IAM role is required to create or update a Pipeline.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 292\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrole_arn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallelism_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClientError \u001b[38;5;28;01mas\u001b[39;00m ce:\n\u001b[1;32m    294\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m ce\u001b[38;5;241m.\u001b[39mresponse[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/workflow/pipeline.py:164\u001b[0m, in \u001b[0;36mPipeline.create\u001b[0;34m(self, role_arn, description, tags, parallelism_config)\u001b[0m\n\u001b[1;32m    162\u001b[0m tags \u001b[38;5;241m=\u001b[39m _append_project_tags(tags)\n\u001b[1;32m    163\u001b[0m tags \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_session\u001b[38;5;241m.\u001b[39m_append_sagemaker_config_tags(tags, PIPELINE_TAGS_PATH)\n\u001b[0;32m--> 164\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrole_arn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallelism_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m update_args(\n\u001b[1;32m    166\u001b[0m     kwargs,\n\u001b[1;32m    167\u001b[0m     Tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[1;32m    168\u001b[0m )\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_session\u001b[38;5;241m.\u001b[39msagemaker_client\u001b[38;5;241m.\u001b[39mcreate_pipeline(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/workflow/pipeline.py:186\u001b[0m, in \u001b[0;36mPipeline._create_args\u001b[0;34m(self, role_arn, description, parallelism_config)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_args\u001b[39m(\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28mself\u001b[39m, role_arn: \u001b[38;5;28mstr\u001b[39m, description: \u001b[38;5;28mstr\u001b[39m, parallelism_config: ParallelismConfiguration\n\u001b[1;32m    173\u001b[0m ):\n\u001b[1;32m    174\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Constructs the keyword argument dict for a create_pipeline call.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \n\u001b[1;32m    176\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;124;03m        A keyword argument dict for calling create_pipeline.\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 186\u001b[0m     pipeline_definition \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefinition\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    188\u001b[0m         PipelineName\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    189\u001b[0m         RoleArn\u001b[38;5;241m=\u001b[39mrole_arn,\n\u001b[1;32m    190\u001b[0m     )\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;66;03m# If pipeline definition is large, upload to S3 bucket and\u001b[39;00m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;66;03m# provide PipelineDefinitionS3Location to request instead.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/workflow/pipeline.py:392\u001b[0m, in \u001b[0;36mPipeline.definition\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefinition\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    386\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Converts a request structure to string representation for workflow service calls.\"\"\"\u001b[39;00m\n\u001b[1;32m    387\u001b[0m     compiled_steps \u001b[38;5;241m=\u001b[39m \u001b[43mStepsCompiler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpipeline_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m        \u001b[49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m        \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpipeline_definition_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipeline_definition_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m--> 392\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    394\u001b[0m     request_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    395\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVersion\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_version,\n\u001b[1;32m    396\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSteps\u001b[39m\u001b[38;5;124m\"\u001b[39m: list_to_request(compiled_steps),\n\u001b[1;32m    404\u001b[0m     }\n\u001b[1;32m    406\u001b[0m     request_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipelineExperimentConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m interpolate(\n\u001b[1;32m    407\u001b[0m         request_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipelineExperimentConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m], {}, {}, pipeline_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    408\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/workflow/_steps_compiler.py:406\u001b[0m, in \u001b[0;36mStepsCompiler.build\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_count \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot build a pipeline more than once with the same compiler.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 406\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_queue_and_build\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_steps\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/workflow/_steps_compiler.py:390\u001b[0m, in \u001b[0;36mStepsCompiler._initialize_queue_and_build\u001b[0;34m(self, steps)\u001b[0m\n\u001b[1;32m    388\u001b[0m         compiled_steps\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_condition_step(step))\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 390\u001b[0m         compiled_steps\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_serialize_output_to_json_flag(compiled_steps)\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m compiled_steps\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/workflow/_steps_compiler.py:331\u001b[0m, in \u001b[0;36mStepsCompiler._build_step\u001b[0;34m(self, step)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Build a step.\"\"\"\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m step_compilation_context_manager(\n\u001b[1;32m    320\u001b[0m     pipeline_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipeline_name,\n\u001b[1;32m    321\u001b[0m     step_name\u001b[38;5;241m=\u001b[39mstep\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    329\u001b[0m     function_step_secret_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_step_secret_token,\n\u001b[1;32m    330\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[0;32m--> 331\u001b[0m     request_dict \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupload_runtime_scripts \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mupload_runtime_scripts\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupload_workspace \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mupload_workspace\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/workflow/function_step.py:227\u001b[0m, in \u001b[0;36m_FunctionStep.to_request\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_request\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m RequestType:\n\u001b[1;32m    226\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Gets the request structure for workflow service calls.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 227\u001b[0m     request_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request_dict\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/workflow/steps.py:390\u001b[0m, in \u001b[0;36mConfigurableRetryStep.to_request\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_request\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m RequestType:\n\u001b[1;32m    389\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Gets the request structure for `ConfigurableRetryStep`.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 390\u001b[0m     step_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policies:\n\u001b[1;32m    392\u001b[0m         step_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetryPolicies\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resolve_retry_policy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policies)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/workflow/steps.py:147\u001b[0m, in \u001b[0;36mStep.to_request\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_request\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m RequestType:\n\u001b[1;32m    143\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Gets the request structure for workflow service calls.\"\"\"\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     request_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    146\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mType\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_type\u001b[38;5;241m.\u001b[39mvalue,\n\u001b[0;32m--> 147\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArguments\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marguments\u001b[49m,\n\u001b[1;32m    148\u001b[0m     }\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepends_on:\n\u001b[1;32m    150\u001b[0m         request_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDependsOn\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepends_on)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/workflow/function_step.py:207\u001b[0m, in \u001b[0;36m_FunctionStep.arguments\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m base_job_name \u001b[38;5;241m=\u001b[39m _Job\u001b[38;5;241m.\u001b[39m_get_job_name(job_settings, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc)\n\u001b[1;32m    202\u001b[0m s3_base_uri \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    203\u001b[0m     s3_path_join(job_settings\u001b[38;5;241m.\u001b[39ms3_root_uri, step_compilation_context\u001b[38;5;241m.\u001b[39mpipeline_name)\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step_compilation_context\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m job_settings\u001b[38;5;241m.\u001b[39ms3_root_uri\n\u001b[1;32m    206\u001b[0m )\n\u001b[0;32m--> 207\u001b[0m request_dict \u001b[38;5;241m=\u001b[39m \u001b[43m_Job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjob_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjob_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_job_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43ms3_base_uri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ms3_base_uri\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserialized_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_serialized_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;66;03m# Continue to pop job name if not explicitly opted-in via config\u001b[39;00m\n\u001b[1;32m    217\u001b[0m request_dict \u001b[38;5;241m=\u001b[39m trim_request_dict(request_dict, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrainingJobName\u001b[39m\u001b[38;5;124m\"\u001b[39m, step_compilation_context)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/remote_function/job.py:763\u001b[0m, in \u001b[0;36m_Job.compile\u001b[0;34m(job_settings, job_name, s3_base_uri, func, func_args, func_kwargs, run_info, serialized_data)\u001b[0m\n\u001b[1;32m    760\u001b[0m     request_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTags\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m job_settings\u001b[38;5;241m.\u001b[39mtags\n\u001b[1;32m    762\u001b[0m \u001b[38;5;66;03m# generate other build artifacts including workspace, requirements.txt\u001b[39;00m\n\u001b[0;32m--> 763\u001b[0m request_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInputDataConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43m_generate_input_data_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    764\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjob_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_settings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms3_base_uri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ms3_base_uri\u001b[49m\n\u001b[1;32m    765\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m step_compilation_context:\n\u001b[1;32m    768\u001b[0m     s3_output_path \u001b[38;5;241m=\u001b[39m Join(\n\u001b[1;32m    769\u001b[0m         on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    770\u001b[0m         values\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    775\u001b[0m         ],\n\u001b[1;32m    776\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/remote_function/job.py:1042\u001b[0m, in \u001b[0;36m_generate_input_data_config\u001b[0;34m(job_settings, s3_base_uri)\u001b[0m\n\u001b[1;32m   1023\u001b[0m bootstrap_scripts_s3uri \u001b[38;5;241m=\u001b[39m _prepare_and_upload_runtime_scripts(\n\u001b[1;32m   1024\u001b[0m     spark_config\u001b[38;5;241m=\u001b[39mjob_settings\u001b[38;5;241m.\u001b[39mspark_config,\n\u001b[1;32m   1025\u001b[0m     s3_base_uri\u001b[38;5;241m=\u001b[39ms3_base_uri,\n\u001b[1;32m   1026\u001b[0m     s3_kms_key\u001b[38;5;241m=\u001b[39mjob_settings\u001b[38;5;241m.\u001b[39ms3_kms_key,\n\u001b[1;32m   1027\u001b[0m     sagemaker_session\u001b[38;5;241m=\u001b[39mjob_settings\u001b[38;5;241m.\u001b[39msagemaker_session,\n\u001b[1;32m   1028\u001b[0m )\n\u001b[1;32m   1030\u001b[0m input_data_config \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   1031\u001b[0m     \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m   1032\u001b[0m         ChannelName\u001b[38;5;241m=\u001b[39mRUNTIME_SCRIPTS_CHANNEL_NAME,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1039\u001b[0m     )\n\u001b[1;32m   1040\u001b[0m ]\n\u001b[0;32m-> 1042\u001b[0m local_dependencies_path \u001b[38;5;241m=\u001b[39m \u001b[43mRuntimeEnvironmentManager\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msnapshot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_settings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdependencies\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m step_compilation_context:\n\u001b[1;32m   1045\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _tmpdir() \u001b[38;5;28;01mas\u001b[39;00m tmp_dir:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sagemaker/remote_function/runtime_environment/runtime_environment_manager.py:130\u001b[0m, in \u001b[0;36mRuntimeEnvironmentManager.snapshot\u001b[0;34m(self, dependencies)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_file_exists(dependencies)\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dependencies\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInvalid dependencies provided: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdependencies\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid dependencies provided: \"cloud/\""
     ]
    }
   ],
   "source": [
    "pipeline.upsert(role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify after successful pipeline run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from steps.deploy import deploy\n",
    "import boto3\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to endpoint name\n",
    "endpoint_name=\"stock-pipeline-endpoint-20250221-234058\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 30\n",
    "input_data = np.random.rand(sequence_length, 4).tolist()  \n",
    "# Ensure the input matches the expected shape: [seq_len, 4]\n",
    "# endpoint_name=\"https://runtime.sagemaker.us-east-1.amazonaws.com/endpoints/stock-pipeline-endpoint-20250221-234058/invocatio\n",
    "endpoint_name=\"stock-pipeline-endpoint-20250221-234058\"\n",
    "\n",
    "# Convert to JSON\n",
    "input_json = json.dumps(input_data)\n",
    "\n",
    "# Call the endpoint\n",
    "try:\n",
    "    runtime = boto3.client('sagemaker-runtime')\n",
    "    print(f\"Invoking endpoint: {endpoint_name}\")\n",
    "    response = runtime.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        ContentType='application/json',\n",
    "        Body=input_json\n",
    "    )\n",
    "    \n",
    "    # Parse the response\n",
    "    result = json.loads(response['Body'].read().decode())\n",
    "    # logger.info(f\"Prediction: {result}\")\n",
    "    print(f\"Prediction from endpoint {endpoint_name}: {result}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error invoking endpoint: {e}\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
